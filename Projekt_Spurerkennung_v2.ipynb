{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a77db10",
   "metadata": {},
   "source": [
    "# Projekt: Erkennung von Spurmarkierungen\n",
    "In diesem Projekt sollen Spurmarkierungen in zwei bestehenden Datensätzen erkannt werden: \n",
    "1. Udacity Nanodegree \"Self-Driving Car Engineer\" (https://www.udacity.com/course/self-driving-car-engineer-nanodegree--nd0013)\n",
    "2. KITTI-Datensatz zur Erkennung von Spurmarkierungen (http://www.cvlibs.net/datasets/kitti/eval_road.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29415ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print('Willkommen beim Projekt \"Erkennung von Spurmarkierungen\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a530612a",
   "metadata": {},
   "source": [
    "# Exkurs 1: Kamerakalibrierung zur Entzerrung der Bilder\n",
    "Die vorhandenen Bilder sind aufgrund der Linsen- und Kameraeigenschaften verzerrt. Entzerren Sie die Bilder mithilfe der Kamerakalibrierungsroutinen von OpenCV (https://docs.opencv.org/4.5.3/dc/dbb/tutorial_py_calibration.html) und den aufgezeichneten Bildern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9006c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.cvtColor(cv.imread('./img/Udacity/calib/calibration1.jpg'), cv.COLOR_BGR2RGB)\n",
    "plt.imshow(img1)\n",
    "plt.title('Kalibrierungsbild')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65719edd",
   "metadata": {},
   "source": [
    "# Exkurs 2: Perspektivtransformation\n",
    "Durch die Kameraperspektive wird die Krümmung der gefundenen Spurmarkierungen nicht der realen Fahrstreifenkrümmung entsprechen. Transformieren Sie daher die Bilder der Kameraperspektive in eine Vogelperspektive, die der realen Fahrstreifenkrümmung entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4109f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# einlesen eines Beispielbildes\n",
    "img1 = cv.imread('./img/Udacity/image001.jpg', -1)\n",
    "plt.imshow(cv.cvtColor(img1, cv.COLOR_BGR2RGB))\n",
    "plt.title('Spurmarkierungen')\n",
    "plt.show()\n",
    "\n",
    "# definieren Sie die für eine Perspektivtransformation notwendigen Quell- und Zielpunkte\n",
    "src = np.float32(...)\n",
    "dst = np.float32(...)\n",
    "\n",
    "M = cv.getPerspectiveTransform(src,dst)\n",
    "img1_warp = cv.warpPerspective(img1,M,(img1.shape[1], img1.shape[0]))\n",
    "plt.imshow(cv.cvtColor(img1_warp, cv.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd5355",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Erkennung von Fahrbahnmarkierungen\n",
    "Erkennen Sie die Fahrbahnmarkierungen bzw. Fahrstreifen auf den Bildquellen von Udacity. Wenden Sie dabei die aus der Vorlesung bekannten Verfahren an. Gerne dürfen Sie auch weitere Verfahren aus anderen Quellen verwenden. Folgende Ziele müssen bei der finalen Abgabe erreicht werden: \n",
    "- **Segmentierung**: schränken Sie das Bild auf den Bereich ein, in dem sich die Spurmarkierungen befinden\n",
    "- **Vorverarbeitung**: führen Sie eine Kamerakalibrierung (für Udacity-Bildquellen) und die Perspektivtransformation durch\n",
    "- **Farbräume, Histogramme**: erkennen Sie die Spurmarkierungen in den Farben der angegebenen Quellen. Sofern weitere Spurmarkierungen auf dem Bild gefunden werden, müssen diejenigen Spurmarkierungen priorisiert werden, die die eigene Fahrspur begrenzen\n",
    "- **Allgemeines**: Die Verarbeitung von Bildern muss in Echtzeit stattfinden --> Ziel: > 20 FPS\n",
    "- **Allgemeines**: Beschleunigen Sie die Verarbeitung durch weitere Maßnahmen weitere Maßnahmen überlegen (bspw. Erkennung der Spurmarkierung in den ersten Frames, Tracking der Spurmarkierung in weiteren Frames solange, bis sich Spurmarkierungspositionen zu stark ändern)\n",
    "- **Minimal**: relevante Spurmarkierungen werden im Video \"project_video\" durchgehend erkannt \n",
    "- **Zusatz**: relevante Spurmarkierungen werden im Video \"challenge_video\" und \"harder_challenge_video\" durchgehend erkannt\n",
    "- **Zusatz**: relevante Spurmarkierungen werden auf den Datensatz KITTI angewendet. Welche Anpassungen müssen vorgenommen werden, damit Ihr Algorithmus übertragen werden kann?\n",
    "- **Zusatz**: Erarbeiten Sie weitere Maßnahmen zur Geschwindigkeitsverbesserung Ihres Algorithmus\n",
    "- **Zusatz**: Erkennen Sie Objekte im Bild und visualisieren Sie diese (z.B. weitere Fahrzeuge, Motorräder, etc.)\u000bDie Objekterkennung bitte so implementieren, dass sie deaktivierbar ist und nicht in FPS-Berechnung einzahlt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a3f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    # Retrieve the number of color channels of the image.\n",
    "    channel_count = img.shape[2]\n",
    "    # Create a match color with the same color channel counts.\n",
    "    match_mask_color = (255,) * channel_count\n",
    "      \n",
    "    # Fill inside the polygon\n",
    "    cv.fillPoly(mask, np.array([vertices],np.int32), match_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def process_frame(frame):\n",
    "    img1_hsv = cv.cvtColor(frame, cv.COLOR_RGB2HSV)\n",
    "    #plt.imshow(frame)\n",
    "    #plt.show()\n",
    "\n",
    "    height = len(img1_hsv)\n",
    "    width = len(img1_hsv[0])\n",
    "\n",
    "    # Set coordinates for a triangle from the bottom left and right corners to the middle\n",
    "    region_of_interest_vertices = [\n",
    "    [0, height],\n",
    "    [width / 2, height / 2],\n",
    "    [width, height],\n",
    "    ]   \n",
    "\n",
    "    # Filter region of interest\n",
    "    img1_hsv = region_of_interest(img1_hsv, region_of_interest_vertices)\n",
    "\n",
    "    # Uses mask to filter colors\n",
    "    mask_white = cv.inRange(img1_hsv, (60,0,220), (110,10,255))\n",
    "    mask_yellow = cv.inRange(img1_hsv, (10, 30, 220), (255, 255, 255))\n",
    "    filtered_frame = mask_white + mask_yellow\n",
    "\n",
    "    # Dilate lane-lines to make them more visibly\n",
    "    kernel_small5 = np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8')\n",
    "    filtered_frame = cv.dilate(filtered_frame, kernel_small5, iterations=5)\n",
    "\n",
    "    completed_frame = frame.copy()\n",
    "    completed_frame[np.where(filtered_frame==0)] = 0\n",
    "\n",
    "    return completed_frame\n",
    "\n",
    "\n",
    "capture = cv.VideoCapture('img/Udacity/project_video.mp4')\n",
    "frameNr = 0\n",
    "while(True):\n",
    "    success, frame = capture.read() \n",
    "    cv.imshow(\"Current Frame\",process_frame(frame))\n",
    "    frameNr += 1\n",
    "    if cv.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "capture.release()\n",
    "\n",
    "#  !!!!!!!!!!!!!! IMPORTANT !!!!!!!!!!!!!!\n",
    "#  Opens the video in a seperate window\n",
    "#  When the video ends the window crashes and you need to restart your kernen before playing the video again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ade8db",
   "metadata": {},
   "source": [
    "# Ausblick auf weitere Teilaufgaben\n",
    "- Bestimmung der Kurvenkrümmung anhand von Polynom-Fiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5f6feb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e692b8c730dce42c75f6e0bb113cc8b09fa56a397f29a247e19fb3548ba9015"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('DigitaleBildverarbeitung': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
