{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playback interrupted by user.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    - Sets all pixels to black outside of the region of interest defined by given verticies\n",
    "    \"\"\"\n",
    "    # Define a blank matrix that matches the image height/width.\n",
    "    mask = np.zeros_like(img)\n",
    "    # Retrieve the number of color channels of the image.\n",
    "    channel_count = img.shape[2]\n",
    "    # Create a match color with the same color channel counts.\n",
    "    match_mask_color = (255,) * channel_count\n",
    "      \n",
    "    # Fill inside the polygon\n",
    "    cv.fillPoly(mask, np.array([vertices],np.int32), match_mask_color)\n",
    "    \n",
    "    # Returning the image only where mask pixels match\n",
    "    masked_image = cv.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def process_frame(frame):\n",
    "    \"\"\"\n",
    "    - Filters lanes by filtering out all colors not matching the color yellow and white (lane colors)\n",
    "    - Dilates filtered lanes to increase visibility \n",
    "    \"\"\"\n",
    "    img1_hsv = cv.cvtColor(frame, cv.COLOR_RGB2HSV)\n",
    "\n",
    "    height = len(img1_hsv)\n",
    "    width = len(img1_hsv[0])\n",
    "    region_of_interest_vertices = [[0, height],[width / 2, height / 2],[width, height],]   \n",
    "    img_region_of_interest = region_of_interest(img1_hsv, region_of_interest_vertices)\n",
    "\n",
    "    # Filter colors\n",
    "    lower_white = np.array([60,0,220], dtype=np.uint8)\n",
    "    upper_white = np.array([110,10,255], dtype=np.uint8)\n",
    "    left_curve = cv.inRange(img_region_of_interest, lower_white, upper_white)\n",
    "    right_curve = cv.inRange(img_region_of_interest, (15, 40, 230), (255, 255, 255))\n",
    "\n",
    "    # Enlarge lane for better visibility\n",
    "    kernel_small5 = np.array([[0,1,0],[1,1,1],[0,1,0]], 'uint8')\n",
    "    left_curve = cv.dilate(left_curve, kernel_small5, iterations=5)\n",
    "    right_curve = cv.dilate(right_curve, kernel_small5, iterations=5)\n",
    "\n",
    "    left_curve_filtered = frame.copy()\n",
    "    left_curve_filtered[np.where(left_curve==0)] = 0\n",
    "    right_curve_filtered = frame.copy()\n",
    "    right_curve_filtered[np.where(right_curve==0)] = 0\n",
    "\n",
    "    kernel = np.array([[1,1,1],[1,-8,1],[1,1,1]],np.float32)\n",
    "    left_curve_filtered = cv.filter2D(left_curve_filtered,-1,kernel)\n",
    "    right_curve_filtered = cv.filter2D(right_curve_filtered,-1,kernel)\n",
    "\n",
    "    return left_curve_filtered,right_curve_filtered\n",
    "\n",
    "def process_frame_gray_slicing(frame):\n",
    "    \"\"\"\n",
    "    - Second attempt of filtering out the lanes by using slicing of grays\n",
    "    - Failes in certain areas because of not enough contrast between road an lane\n",
    "    \"\"\"\n",
    "    img_grey = cv.cvtColor(frame, cv.COLOR_RGB2HSV)\n",
    "\n",
    "    thresh1 = 90\n",
    "\n",
    "    w = len(img_grey[0])\n",
    "    h = len(img_grey)\n",
    "\n",
    "    height = len(img_grey)\n",
    "    width = len(img_grey[0])\n",
    "    region_of_interest_vertices = [[0, height],[width / 2, height / 2],[width, height],]   \n",
    "    img_region_of_interest = region_of_interest(img_grey, region_of_interest_vertices)\n",
    "\n",
    "    img_region_of_interest_old = cv.cvtColor(img_region_of_interest, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "    img_region_of_interest = np.zeros((h,w), dtype = int)\n",
    "\n",
    "    for i in range(h-1):\n",
    "        for j in range(w-1):\n",
    "            if img_region_of_interest_old[i,j] <= thresh1: \n",
    "                img_region_of_interest[i,j] = 0\n",
    "            else:\n",
    "                img_region_of_interest[i,j] = 255\n",
    "                \n",
    "    plt.imshow(img_region_of_interest)\n",
    "\n",
    "    return img_region_of_interest\n",
    "\n",
    "def process_frame_gray(frame):\n",
    "    \"\"\"\n",
    "    - Attempt at filtering out the lanes by using canny edge detection in combination with houghline detection\n",
    "    \"\"\"\n",
    "    img_grey = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "    edges = cv.Canny(img_grey,100,200,apertureSize = 3)\n",
    "    lines = cv.HoughLines(edges,1,np.pi/180, 200)\n",
    "\n",
    "    lines = [x for x in lines if x is not None]\n",
    "\n",
    "    for r,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*r\n",
    "        y0 = b*r\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv.line(img_grey,(x1,y1), (x2,y2), (0,0,255),2)\n",
    "\n",
    "    return img_grey\n",
    "\n",
    "def findFourVertices(img_filtered):\n",
    "    \"\"\"\n",
    "    - Previously used to detect start and endpoints of lanes\n",
    "    - not used because of bad performance\n",
    "    \"\"\"\n",
    "    height = len(img_filtered)\n",
    "    width = len(img_filtered[0])\n",
    "\n",
    "    startHeight = int(height/1.5)\n",
    "    maxWidth = int(width/2)\n",
    "    points = []\n",
    "\n",
    "    tempHeight = startHeight\n",
    "    valueFound = False\n",
    "    while valueFound == False:\n",
    "        # Top left point\n",
    "        pointCloud = np.where(img_filtered[startHeight][:maxWidth - 1] != 0)\n",
    "        if(len(pointCloud[0]) != 0):\n",
    "            # print(pointCloud)\n",
    "            xMean = int((pointCloud[0][0] + pointCloud[0][-1])/2)\n",
    "            points.append((xMean, startHeight))\n",
    "\n",
    "            valueFound = True\n",
    "        else:\n",
    "            startHeight += 1\n",
    "\n",
    "    startHeight = tempHeight\n",
    "    valueFound = False\n",
    "    while valueFound == False:\n",
    "        # Top right point\n",
    "        pointCloud = np.where(img_filtered[startHeight][maxWidth + 1:] != 0)\n",
    "        if(len(pointCloud[0]) != 0):\n",
    "            xMean = int((pointCloud[0][0] + pointCloud[0][-1])/2)\n",
    "            points.append((xMean, startHeight))\n",
    "            valueFound = True\n",
    "        else:\n",
    "            startHeight += 1\n",
    "\n",
    "    \n",
    "    valueFound = False\n",
    "    startHeight = height - 1\n",
    "    tempHeight = startHeight\n",
    "    while valueFound == False:\n",
    "        # Bottom left point\n",
    "        pointCloud = np.where(img_filtered[startHeight][:maxWidth - 1] != 0)\n",
    "        if(len(pointCloud[0]) != 0):\n",
    "            # print(pointCloud)\n",
    "            xMean = int((pointCloud[0][0] + pointCloud[0][-1])/2)\n",
    "            points.append((xMean, startHeight))\n",
    "            valueFound = True\n",
    "        else:\n",
    "            startHeight -= 1\n",
    "\n",
    "    startHeight = tempHeight\n",
    "    valueFound = False\n",
    "    while valueFound == False:\n",
    "        # Bottom right point\n",
    "        pointCloud = np.where(img_filtered[startHeight][maxWidth + 1:] != 0)\n",
    "        if(len(pointCloud[0]) != 0):\n",
    "            xMean = int((pointCloud[0][0] + pointCloud[0][-1])/2)\n",
    "            points.append((xMean, startHeight))\n",
    "            valueFound = True\n",
    "        else:\n",
    "            startHeight -= 1\n",
    "\n",
    "    print(\"Points: \", points)\n",
    "\n",
    "def curveradius(frame, xleft, xright):\n",
    "    y = np.linspace(0, frame.shape[0]-1, frame.shape[0])\n",
    "    x_m_per_pix = 30.5/720\n",
    "    y_m_per_pix = 3.7/700\n",
    "    y_eval = np.max(y)\n",
    "\n",
    "    curveleft = np.ployfit(y*y_m_per_pix, xleft*x_m_per_pix)\n",
    "    curveright = np.polyfit(y*y_m_per_pix, xright*x_m_per_pix)\n",
    "\n",
    "    curverad_left = ((1 + (2*curveleft[0]*y_eval*y_m_per_pix + curveleft[1])**2)**1.5) / np.absolute(2*curveleft[0])\n",
    "    curverad_right = ((1 + (2*curveright[0]*y_eval*y_m_per_pix + curveright[1])**2)**1.5) / np.absolute(2*curveright[0])\n",
    "\n",
    "    return curverad_left, curverad_right\n",
    "\n",
    "capture = cv.VideoCapture('img/Udacity/project_video.mp4')\n",
    "frameNr = 0\n",
    "newFrameTime = 0\n",
    "prevFrameTime = 0\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while(True):\n",
    "    success, frame = capture.read() \n",
    "    if frameNr == 1 or frameNr == 0:\n",
    "        left_curve, right_curve = process_frame(frame)\n",
    "\n",
    "    if(success):\n",
    "        newFrameTime = time.time()\n",
    "\n",
    "        # Updates detected lanes every 3 seconds in-order to increase performance\n",
    "        if frameNr%3 == 0:\n",
    "            left_curve, right_curve = process_frame(frame)\n",
    "        all_curves = left_curve + right_curve\n",
    "\n",
    "        # Puts a mask over the old frame to improve visibility of the filtered lanes in \"all_curves\"\n",
    "        alpha = 0.4\n",
    "        beta = (1.0 - alpha)\n",
    "        dark_mask = cv.addWeighted(frame, alpha, all_curves, beta, 0.0)\n",
    "        darkened_image = all_curves + dark_mask\n",
    "\n",
    "        # Calcultes FPS\n",
    "        fps = 1/(newFrameTime - prevFrameTime)\n",
    "        prevFrameTime = newFrameTime\n",
    "        fps = int(fps)\n",
    "        fps = str(fps) \n",
    "\n",
    "        # Perspective transformation for curve fitting\n",
    "        old_points = np.float32([[200,720],[1000,720],[460,460],[740,460]])\n",
    "        new_points = np.float32([[0,800],[600,800],[0,0],[600,0]])\n",
    "        perspective_transform = cv.getPerspectiveTransform(old_points,new_points)\n",
    "        new_perspecitve = cv.warpPerspective(darkened_image,perspective_transform,(800,600))\n",
    "        \n",
    "        # Boolean for activating/deactivating perspektive transform\n",
    "        transform_perspective = False\n",
    "\n",
    "        if transform_perspective == True:\n",
    "            cv.putText(darkened_image, fps, (7, 30), font, 1, (100, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.imshow(\"Current Frame\", darkened_image)\n",
    "        else:\n",
    "            cv.putText(new_perspecitve, fps, (7, 30), font, 1, (100, 255, 0), 1, cv.LINE_AA)\n",
    "            cv.imshow(\"Current Frame\", new_perspecitve)\n",
    "\n",
    "        frameNr += 1\n",
    "        key = cv.waitKey(1)\n",
    "        # Control buttons for video playback\n",
    "        # Press P to pause\n",
    "        # Press q to quit\n",
    "        if key == ord(\"q\"):\n",
    "            cv.destroyAllWindows()\n",
    "            print(\"Playback interrupted by user.\")\n",
    "            break\n",
    "        if key == ord('p'):\n",
    "            cv.waitKey(-1) # Wait until any key is pressed\n",
    "    else:\n",
    "        print(\"Playback finished.\")\n",
    "        cv.destroyAllWindows()\n",
    "        capture.release()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bearbeitet Aspekte\n",
    "- Spurerkennung über Farbraumfilterung\n",
    "- Segmentierung des relevanten Bereichs, in welchen die Spur vorkommt\n",
    "- Perspektiven-Transformation für die Vogelperspektiv wurde durchgeführt\n",
    "- Maßnahme zu Verbesserung der Performance/FPS: Zu beginn wird die Spur gefiltert, danach wird die Spur alle 3 Frames aktualisiert, da keine große Änderungen innerhalb der Zeitspanne passieren wodurch aufwendige Berechnungen nur alle 3 Frames passieren und die FPS höher sind"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e692b8c730dce42c75f6e0bb113cc8b09fa56a397f29a247e19fb3548ba9015"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('DigitaleBildverarbeitung': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
